import kagglehub
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
import plotly.express as px

# Scikit-learn imports
from sklearn import tree
from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix
from sklearn.inspection import PartialDependenceDisplay
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans, DBSCAN

# Imbalanced learn
from imblearn.over_sampling import RandomOverSampler


# Descargar el dataset de Kaggle (pima-indians-diabetes-database)
path = kagglehub.dataset_download("uciml/pima-indians-diabetes-database")


# Cargar el archivo CSV desde el path
diabetes = pd.read_csv(f"{path}/diabetes.csv", na_values=['?'])


# Ver la distribuci√≥n de las clases en la columna 'Outcome' de la base de datos original
class_distribution = diabetes['Outcome'].value_counts()


# Filtrar las clases 0 y 1
class_0 = diabetes[diabetes['Outcome'] == 0]
class_1 = diabetes[diabetes['Outcome'] == 1]

# Eliminar aleatoriamente 200 ejemplos de la clase 0 para balancear
class_0_reduced = class_0.sample(n=len(class_0) - 200, random_state=42)

# Combinar las clases balanceadas
diabetes_balanced = pd.concat([class_0_reduced, class_1])


# Balanceo de datos
# Manejo de valores nulos (se eliminan filas con NaN)
diabetes_balanced.dropna(inplace=True)

# Separar variables predictoras (X) y variable objetivo (y)
X = diabetes_balanced.drop(columns=['Outcome'])  # 'Outcome' es la variable objetivo
y = diabetes_balanced['Outcome']


# Divisi√≥n con StratifiedKFold (K-folds)
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=22)
for train_index, test_index in skf.split(X, y):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

# Definir modelos y sus hiperpar√°metros
models = {
    "LogisticRegression": {
        "model": LogisticRegression(),
        "params": {
            "model__C": [0.01, 0.1, 1, 10, 100],  # A√±adimos m√°s valores para C
            "model__solver": ["liblinear", "saga"],  # Opci√≥n 'saga' para problemas grandes
            "model__penalty": ["l1", "l2"],  # Probar diferentes penalizaciones
            "model__max_iter": [100, 200]  # Iteraciones adicionales si es necesario
        }
    },
    "RandomForest": {
        "model": RandomForestClassifier(),
        "params": {
            "model__n_estimators": [50, 100, 200],  # M√°s √°rboles
            "model__max_depth": [3, 5, 10, None],  # Profundidades adicionales
            "model__min_samples_split": [2, 5, 10],  # Divisiones m√≠nimas para cada nodo
            "model__min_samples_leaf": [1, 2, 5],  # Hojas m√≠nimas para cada nodo
            "model__bootstrap": [True, False]  # Si usar bootstrap o no
        }
    },
    "DecisionTree": {
        "model": DecisionTreeClassifier(),
        "params": {
            "model__max_depth": [3, 5, 10, None],  # M√°s profundidades
            "model__min_samples_split": [2, 5, 10],  # Divisiones m√≠nimas
            "model__min_samples_leaf": [1, 2, 5],  # Hojas m√≠nimas
            "model__criterion": ["gini", "entropy"]  # Diferentes criterios de divisi√≥n
        }
    }
}

# Ejecutar validaci√≥n cruzada para cada modelo, eligiendo seg√∫n Recall
best_model = None
best_score = 0
results = []

for name, config in models.items():
    print(f"\nüîç Evaluando {name} con validaci√≥n cruzada...")

    # Crear pipeline con estandarizaci√≥n + modelo
    pipeline = Pipeline([("scaler", StandardScaler()), ("model", config["model"])])

    # GridSearch con validaci√≥n cruzada (CV=10)
    grid_search = GridSearchCV(pipeline, config["params"], cv=10, scoring="recall", n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Guardar los resultados en un DataFrame
    results.append({
        "Modelo": name,
        "Mejor Recall CV": grid_search.best_score_,
        "Mejores Hiperpar√°metros": grid_search.best_params_
    })

    # Guardar el mejor modelo seg√∫n recall
    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_model = grid_search.best_estimator_

# Convertir resultados en un DataFrame
results_df = pd.DataFrame(results)


# Evaluar el mejor modelo en el conjunto de prueba
y_pred = best_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
test_recall = recall_score(y_test, y_pred)  # Sensibilidad (recall)



# Graficar el √°rbol de decisi√≥n en caso de que este sea el mejor modelo
if isinstance(best_model, Pipeline):
    # Acceder al √°rbol de decisi√≥n en el pipeline
    tree_model = best_model.named_steps['model']  # 'model' is the step name from the pipeline


    
# Mostrar la matriz de confusi√≥n del modelo con mejor resultado
# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)

# Obtener el nombre del modelo de best_model
model_name = best_model.named_steps["model"].__class__.__name__  # Obtener el nombre del modelo


# Crear la aplicaci√≥n de Streamlit
# Title of the Streamlit app
st.title("Diabetes Prediction Model Results")

#Create tabs
tab1, tab2, tab3 = st.tabs(["EDA", "Classification", "Clustering"])


#-------------------------------- Tab 1: EDA --------------------------------
with tab1:
    st.subheader("üìä Model Results")
    st.write("Show model performance, accuracy, recall, confusion matrix, etc.")


#-------------------------------- Tab 2: Classification --------------------------------
with tab2:

    diabetes['Outcome'] = diabetes['Outcome'].astype(int)

    # Show dataset preview
    if st.checkbox("Show raw data"):
        st.write(diabetes.head())

    # Class distribution
    st.subheader("Class Distribution in Original Dataset")
    class_distribution = diabetes['Outcome'].value_counts()
    st.bar_chart(class_distribution)

    # Balancing dataset with undersampling
    class_0 = diabetes[diabetes['Outcome'] == 0]
    class_1 = diabetes[diabetes['Outcome'] == 1]
    class_0_reduced = class_0.sample(n=len(class_0) - 200, random_state=42)
    diabetes_balanced = pd.concat([class_0_reduced, class_1])

    # Show balanced class distribution
    st.subheader("Class Distribution After Balancing")
    balanced_class_distribution = diabetes_balanced['Outcome'].value_counts()
    st.bar_chart(balanced_class_distribution)


    st.subheader("Model Performance")
    st.write(results_df)


    #Decision tree
    st.subheader("Decision tree result")
    # Acceder al √°rbol de decisi√≥n en el pipeline
    tree_model = best_model.named_steps['model']  # 'model' is the step name from the pipeline

    # Graficar el √°rbol de decisi√≥n
    fig, ax = plt.subplots(figsize=(12, 8))  # Define figure and axis
    plot_tree(tree_model, filled=True, feature_names=X.columns, rounded=True, ax=ax)  # Use ax
    st.pyplot(fig)  # Display in Streamlit

    # Confusion matrix
    st.subheader("Confusion Matrix of Best Model")
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No Diabetes", "Diabetes"], yticklabels=["No Diabetes", "Diabetes"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    st.pyplot(fig)

    # Show accuracy and recall
    st.subheader("Final Model Performance")
    st.write(f"**Best Model:** {model_name}")
    st.write(f"**Accuracy:** {test_accuracy:.4f}")
    st.write(f"**Recall:** {test_recall:.4f}")


#-------------------------------- Tab 1: EDA --------------------------------
with tab3:
    
    dataset = diabetes
    
    # Class distribution
    st.subheader("Class Distribution in Original Dataset")
    class_distribution = diabetes['Outcome'].value_counts()
    st.bar_chart(class_distribution)

    #Balancear los datos con oversampling
    oversampler = RandomOverSampler(random_state=42)
    X_resampled, y_resampled = oversampler.fit_resample(dataset.drop(columns=['Outcome']), dataset['Outcome'])

    # Crear un nuevo DataFrame equilibrado
    df = pd.DataFrame(X_resampled, columns=dataset.drop(columns=['Outcome']).columns)
    df['Outcome'] = y_resampled

    #Shows the pairplot of the variables 
    st.subheader("variables - pairplot")
    fig = sns.pairplot(df, hue="Outcome")
    st.pyplot(fig)

    #Eliminar variables con poco peso
    df = df.drop(columns=['SkinThickness', 'Insulin', 'DiabetesPedigreeFunction'])  # Eliminar variables del dataframe


    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(df.drop(columns=['Outcome'], errors='ignore'))


    # Reducci√≥n de dimensionalidad con PCA para visualizaci√≥n
    pca = PCA(n_components=2)
    data_pca = pca.fit_transform(data_scaled)


    # Definir min_samples (prueba con 5 o 10)
    min_samples = 10

    # Calcular las distancias al k-√©simo vecino m√°s cercano
    neighbors = NearestNeighbors(n_neighbors=min_samples)
    neighbors_fit = neighbors.fit(data_scaled)
    distances, indices = neighbors_fit.kneighbors(data_scaled)


    # Ordenar y graficar las distancias
    distances = np.sort(distances[:, -1])  # Tomar la √∫ltima distancia (k-√©simo vecino)

    # Crear imagen
    st.subheader("Gr√°fico para encontrar Epsilon (k-Distance)")
    fig, ax = plt.subplots()
    ax.plot(distances)
    ax.set_xlabel("Sorted Points")
    ax.set_ylabel(f"Distance to {min_samples}-th Nearest Neighbor")
    ax.set_title("k-Distance Graph for Finding Epsilon")

    # Mostrar gr√°fico en Streamlit
    st.pyplot(fig)

    # Aplicar DBSCAN
    dbscan = DBSCAN(eps=1.4, min_samples=10)
    dbscan_labels = dbscan.fit_predict(data_scaled)

    #Plot DBSCAN
    st.subheader("Clusters identificados con DBSCAN")
    fig_dbscan = px.scatter(data_pca, 
                            x=data_pca[:,0], 
                            y=data_pca[:,1], 
                            color=dbscan_labels.astype(str),  # Convertir a string para evitar escalas num√©ricas en la leyenda
                            title="Clusters Identificados con DBSCAN",
                            labels={"PC1": "Componente Principal 1", "PC2": "Componente Principal 2", "color": "Cluster DBSCAN"},
                            opacity=0.7)  # Hacer los puntos semitransparentes para mejor visualizaci√≥n

    st.pyplot(fig_dbscan)

    if 'Outcome' in df.columns:
        df['DBSCAN_Cluster'] = dbscan_labels  # Agregar la columna de clusters al dataframe

        # Calcular distribuci√≥n de Outcome por cluster
        outcome_distribution = df.groupby('DBSCAN_Cluster')['Outcome'].value_counts(normalize=True).unstack()

        # Mostrar tabla en Streamlit
        st.subheader("Distribuci√≥n de Outcome por Cl√∫ster (DBSCAN)")
        st.write(outcome_distribution)  # Mostrar tabla en la app


    # Agrupar y calcular frecuencia y proporci√≥n
    df_count = df.groupby(["DBSCAN_Cluster", "Outcome"]).size().reset_index(name="Frecuencia")
    df_total = df.groupby("DBSCAN_Cluster").size().reset_index(name="Total")
    df_count = df_count.merge(df_total, on="DBSCAN_Cluster")
    df_count["Proporci√≥n"] = df_count["Frecuencia"] / df_count["Total"]

    # Convertir Outcome a string para que Plotly lo trate como categor√≠a
    df_count["Outcome"] = df_count["Outcome"].astype(str)

    # Crear gr√°fico interactivo con Plotly
    fig = px.bar(df_count, 
                x="DBSCAN_Cluster", 
                y="Frecuencia", 
                color="Outcome",
                text=df_count["Proporci√≥n"].apply(lambda x: f"{x:.2%}"),  # Mostrar porcentaje
                barmode="group",  # Barras agrupadas (lado a lado)
                labels={"DBSCAN_Cluster": "Cl√∫ster DBSCAN", "Frecuencia": "Frecuencia", "Outcome": "Outcome"},
                title="Distribuci√≥n de Outcome en Clusters DBSCAN")

    # Mostrar gr√°fico en Streamlit
    st.plotly_chart(fig)

    # Interpretaci√≥n en texto
    st.write("* DBSCAN identific√≥ un gran grupo de "outliers" (Cluster -1) con un 45% de diab√©ticos. Esto significa que muchos puntos no se pudieron agrupar bien.")
    st.write("* El √∫nico cluster grande (Cluster 0) tiene un 50-50 de pacientes diab√©ticos y no diab√©ticos, lo que indica que DBSCAN no logr√≥ encontrar una separaci√≥n clara entre los grupos.")
    st.write("No gener√≥ m√∫ltiples clusters √∫tiles ‚Üí Podr√≠a significar que los datos no tienen agrupaciones naturales bien definidas.")
